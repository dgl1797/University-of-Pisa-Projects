{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015851b0",
   "metadata": {},
   "source": [
    "## ANALYSIS WITH LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbc6559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_5340/110077151.py, line 107)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\digia\\AppData\\Local\\Temp/ipykernel_5340/110077151.py\"\u001b[1;36m, line \u001b[1;32m107\u001b[0m\n\u001b[1;33m    Challenger  11910.223708\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ranks_df = pd.read_csv(\"../csv_sources/leveled_for_rarity.csv\").drop([\"index\", \"crowns\"], axis=\"columns\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"troop\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"troop\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"building\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"building\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"spell\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"spell\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"common\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"common\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"rare\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"rare\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"epic\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"epic\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"legendary\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"legendary\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"elixir\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"elixir\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"conf_synergy\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"conf_synergy\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"lift_synergy\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"lift_synergy\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"levelSum\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"levelSum\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"avgSpeed\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"avgSpeed\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"avgSpellDuration\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"avgSpellDuration\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalHP\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalHP\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalDMG\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalDMG\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"avgAS\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"avgAS\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalUnitsCount\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalUnitsCount\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"abilityCount\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"abilityCount\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"avgRange\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"avgRange\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalGroundT\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalGroundT\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalAirT\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalAirT\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalBuildingT\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalBuildingT\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalBuffCount\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalBuffCount\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ranks_df[[\"rank\", \"totalProjectiles\"]].groupby(\"rank\").mean())\n",
    "print(ranks_df[[\"rank\", \"totalProjectiles\"]].groupby(\"rank\").std())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "ranks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eccee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, VarianceThreshold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from random import randrange\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "y = np.array([x for x in ranks_df[\"rank\"]])\n",
    "X = np.array([x for x in ranks_df.drop([\"rank\"], axis=\"columns\").values])\n",
    "\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'Recall': make_scorer(recall_score, average=\"macro\", zero_division=0),\n",
    "    'F-Measure': make_scorer(f1_score, average=\"macro\", zero_division=0)\n",
    "}\n",
    "\n",
    "def converter(df):\n",
    "    scores = {\n",
    "        'fit_time': df['fit_time'],\n",
    "        'score_time': df['score_time'],\n",
    "        'test_Accuracy': df['test_Accuracy'],\n",
    "        'test_Precision': df['test_Precision'],\n",
    "        'test_Recall': df['test_Recall'],\n",
    "        'test_F-Measure': df['test_F-Measure']\n",
    "    }\n",
    "    estimators = df['estimator']\n",
    "    accuracies = df['test_Accuracy']\n",
    "    for key in scores.keys():\n",
    "        if \"test_\" in key:\n",
    "            scores[key] = [f\"{scores[key].mean() * 100: .2f}%\"]\n",
    "        else:\n",
    "            scores[key] = [f\"{scores[key].mean(): .2f}\"]\n",
    "    return [pd.DataFrame(scores), estimators, accuracies]\n",
    "\n",
    "def feat_extraction(estimators, avoid_scores = False):\n",
    "    features_per_fold = {}\n",
    "    fold_index = 0\n",
    "    for estim in estimators:\n",
    "        fold_index += 1\n",
    "        feature = 0\n",
    "        sel_features = {}\n",
    "        feat_scores = []\n",
    "        if not avoid_scores:\n",
    "            feat_scores = estim['feat_sel'].scores_\n",
    "        for selected in estim['feat_sel'].get_support():\n",
    "            feature+=1\n",
    "            if(selected == True):\n",
    "                if len(feat_scores) > 0:\n",
    "                    sel_features[ranks_df.columns[feature]] = [feat_scores[feature-1]]\n",
    "                else:\n",
    "                    sel_features[ranks_df.columns[feature]] = True\n",
    "        features_per_fold[f\"fold_{fold_index}\"] = sel_features\n",
    "    return pd.DataFrame(features_per_fold).transpose()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7b0ef",
   "metadata": {},
   "source": [
    "### ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoted_pipeline = Pipeline([\n",
    "    ('sampler', SMOTE()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "unsmoted_pipeline = Pipeline([\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "#######################################################\n",
    "kbest_smoted = Pipeline([\n",
    "    ('feat_sel', SelectKBest(chi2, k=20)),\n",
    "    ('sampler', SMOTE()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "kbest_unsmoted = Pipeline([\n",
    "    ('feat_sel', SelectKBest(chi2, k=20)),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "########################################################\n",
    "kbest_smoted_mutual = Pipeline([\n",
    "    ('feat_sel', SelectKBest(mutual_info_classif, k=20)),\n",
    "    ('sampler', SMOTE()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "kbest_unsmoted_mutual = Pipeline([\n",
    "    ('feat_sel', SelectKBest(mutual_info_classif, k=20)),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "########################################################\n",
    "VT_smoted = Pipeline([\n",
    "    ('feat_sel', VarianceThreshold(threshold=0.7)),\n",
    "    ('sampler', SMOTE()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "VT_unsmoted = Pipeline([\n",
    "    ('feat_sel', VarianceThreshold(threshold=0.7)),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "metricsComparison = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c490eea",
   "metadata": {},
   "source": [
    "### SMOTE NO ATTRIBUT SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoted_ = cross_validate(smoted_pipeline, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "mean_smoted, smoted_estimators, accuracies = converter(smoted_)\n",
    "\n",
    "metricsComparison['J48 + SMOTE'] = [accuracies]\n",
    "\n",
    "mean_smoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620e2e19",
   "metadata": {},
   "source": [
    "### NO SMOTE NO ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsmoted_ = cross_validate(unsmoted_pipeline, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "mean_unsmoted, unsmoted_estimators, accuracies = converter(unsmoted_)\n",
    "\n",
    "metricsComparison['J48'] = [accuracies]\n",
    "\n",
    "mean_unsmoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a0e85",
   "metadata": {},
   "source": [
    "### SMOTE KBEST SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21017b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_smoted_ = cross_validate(kbest_smoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "\n",
    "mean_kbest_smoted, kbest_smoted_estimators, accuracies = converter(kbest_smoted_)\n",
    "    \n",
    "kbest_features = feat_extraction(kbest_smoted_estimators)\n",
    "kbest_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198df994",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48 + SMOTE + KBEST and chi2'] = [accuracies]\n",
    "\n",
    "mean_kbest_smoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d375d",
   "metadata": {},
   "source": [
    "### NO SMOTE KBEST SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fff8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_unsmoted_scores = cross_validate(kbest_unsmoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "mean_kbest_unsmoted, kbest_unsmoted_estimators, accuracies = converter(kbest_unsmoted_scores)\n",
    "\n",
    "kbest_unsmoted_features = feat_extraction(kbest_unsmoted_estimators)\n",
    "\n",
    "kbest_unsmoted_features.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f91b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48 + KBEST and chi2'] = [accuracies]\n",
    "\n",
    "mean_kbest_unsmoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac22c65",
   "metadata": {},
   "source": [
    "### KBEST SELECTOR WITH MUTUAL INFO CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a727f",
   "metadata": {},
   "source": [
    "###### SMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ed51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_smoted_mutual_ = cross_validate(kbest_smoted_mutual, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "kbest_smoted_mutual_scores, kbest_smoted_mutual_estimators, accuracies = converter(kbest_smoted_mutual_)\n",
    "\n",
    "kbest_smoted_mutual_features = feat_extraction(kbest_smoted_mutual_estimators)\n",
    "kbest_smoted_mutual_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48 + SMOTE + KBEST and mutual_info'] = [accuracies]\n",
    "\n",
    "kbest_smoted_mutual_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a9e129",
   "metadata": {},
   "source": [
    "###### UNSMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_unsmoted_mutual_ = cross_validate(kbest_unsmoted_mutual, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "kbest_unsmoted_mutual_scores, kbest_unsmoted_mutual_estimators, accuracies = converter(kbest_unsmoted_mutual_)\n",
    "\n",
    "kbest_unsmoted_mutual_features = feat_extraction(kbest_unsmoted_mutual_estimators)\n",
    "kbest_unsmoted_mutual_features.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9afe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48 + KBEST and mutual_info'] = [accuracies]\n",
    "\n",
    "kbest_unsmoted_mutual_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35071e",
   "metadata": {},
   "source": [
    "### VARIANCE THRESHOLD SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf03b4",
   "metadata": {},
   "source": [
    "###### SMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_smoted_ = cross_validate(VT_smoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "VT_smoted_scores, VT_smoted_estimators, accuracies = converter(VT_smoted_)\n",
    "\n",
    "VT_smoted_features = feat_extraction(VT_smoted_estimators, avoid_scores=True)\n",
    "VT_smoted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31792ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48 + SMOTE + Variance Threshold'] = [accuracies]\n",
    "\n",
    "VT_smoted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce8579",
   "metadata": {},
   "source": [
    "###### UNSMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1326b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_unsmoted_ = cross_validate(VT_unsmoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "VT_unsmoted_scores, VT_unsmoted_estimators, accuracies = converter(VT_unsmoted_)\n",
    "\n",
    "VT_unsmoted_features = feat_extraction(VT_unsmoted_estimators, avoid_scores=True)\n",
    "VT_unsmoted_features.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48 + Variance Threshold'] = [accuracies]\n",
    "\n",
    "VT_unsmoted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89272775",
   "metadata": {},
   "source": [
    "### BOX PLOT OF RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a15595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "for metric in metricsComparison:\n",
    "    for m in metricsComparison[metric]:\n",
    "        final_dict[metric] = m\n",
    "mc_df = pd.DataFrame(final_dict)\n",
    "mc_df.plot.box(return_type='axes', figsize=(40,20), grid=True, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c94987",
   "metadata": {},
   "source": [
    "## ANALYSIS WITHOUT LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a07c64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ranks_nolevel_df = ranks_df.drop([\"levelSum\"], axis=\"columns\")\n",
    "ranks_nolevel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eae7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([x for x in ranks_nolevel_df[\"rank\"]])\n",
    "X = np.array([x for x in ranks_nolevel_df.drop([\"rank\"], axis=\"columns\").values])\n",
    "metricsComparison = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca330dc",
   "metadata": {},
   "source": [
    "### SMOTE NO ATTRIBUT SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004c97a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5340/1590774820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msmoted_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmoted_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmean_smoted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmoted_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmoted_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmetricsComparison\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'J48+SMOTE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validate' is not defined"
     ]
    }
   ],
   "source": [
    "smoted_ = cross_validate(smoted_pipeline, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "mean_smoted, smoted_estimators, accuracies = converter(smoted_)\n",
    "\n",
    "metricsComparison['J48+SMOTE'] = [accuracies]\n",
    "\n",
    "mean_smoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e42faf2",
   "metadata": {},
   "source": [
    "### NO SMOTE NO ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsmoted_ = cross_validate(unsmoted_pipeline, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "mean_unsmoted, unsmoted_estimators, accuracies = converter(unsmoted_)\n",
    "\n",
    "metricsComparison['J48'] = [accuracies]\n",
    "\n",
    "mean_unsmoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4349622",
   "metadata": {},
   "source": [
    "### SMOTE KBEST SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ffad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_smoted_ = cross_validate(kbest_smoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "\n",
    "mean_kbest_smoted, kbest_smoted_estimators, accuracies = converter(kbest_smoted_)\n",
    "    \n",
    "kbest_features = feat_extraction(kbest_smoted_estimators)\n",
    "kbest_features.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280228dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48+SMOTE+KBEST and chi2'] = [accuracies]\n",
    "\n",
    "mean_kbest_smoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55f5ff",
   "metadata": {},
   "source": [
    "### NO SMOTE KBEST SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_unsmoted_scores = cross_validate(kbest_unsmoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "mean_kbest_unsmoted, kbest_unsmoted_estimators, accuracies = converter(kbest_unsmoted_scores)\n",
    "\n",
    "kbest_unsmoted_features = feat_extraction(kbest_unsmoted_estimators)\n",
    "\n",
    "kbest_unsmoted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48+KBEST and chi2'] = [accuracies]\n",
    "\n",
    "mean_kbest_unsmoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd064d",
   "metadata": {},
   "source": [
    "### KBEST SELECTOR WITH MUTUAL INFO CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ddc220",
   "metadata": {},
   "source": [
    "###### SMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_smoted_mutual_ = cross_validate(kbest_smoted_mutual, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "kbest_smoted_mutual_scores, kbest_smoted_mutual_estimators, accuracies = converter(kbest_smoted_mutual_)\n",
    "\n",
    "kbest_smoted_mutual_features = feat_extraction(kbest_smoted_mutual_estimators)\n",
    "kbest_smoted_mutual_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48+SMOTE+KBest and mutual info'] = [accuracies]\n",
    "\n",
    "kbest_smoted_mutual_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3d1d5",
   "metadata": {},
   "source": [
    "###### UNSMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cebe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_unsmoted_mutual_ = cross_validate(kbest_unsmoted_mutual, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "kbest_unsmoted_mutual_scores, kbest_unsmoted_mutual_estimators, accuracies = converter(kbest_unsmoted_mutual_)\n",
    "\n",
    "kbest_unsmoted_mutual_features = feat_extraction(kbest_unsmoted_mutual_estimators)\n",
    "kbest_unsmoted_mutual_features.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48+KBest and mutual info'] = [accuracies]\n",
    "\n",
    "kbest_unsmoted_mutual_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab5105",
   "metadata": {},
   "source": [
    "### VARIANCE THRESHOLD SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9cfadd",
   "metadata": {},
   "source": [
    "###### SMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3002fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_smoted_ = cross_validate(VT_smoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "VT_smoted_scores, VT_smoted_estimators, accuracies = converter(VT_smoted_)\n",
    "\n",
    "VT_smoted_features = feat_extraction(VT_smoted_estimators, avoid_scores=True)\n",
    "VT_smoted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae17408",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48+SMOTE+VT'] = [accuracies]\n",
    "\n",
    "VT_smoted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429be3d6",
   "metadata": {},
   "source": [
    "###### UNSMOTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_unsmoted_ = cross_validate(VT_unsmoted, X, y, scoring=scoring, cv=skf, n_jobs=4, return_estimator=True)\n",
    "VT_unsmoted_scores, VT_unsmoted_estimators, accuracies = converter(VT_unsmoted_)\n",
    "\n",
    "VT_unsmoted_features = feat_extraction(VT_unsmoted_estimators, avoid_scores=True)\n",
    "VT_unsmoted_features.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d912bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsComparison['J48+VT'] = [accuracies]\n",
    "\n",
    "VT_unsmoted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f12f26",
   "metadata": {},
   "source": [
    "### BOX PLOT OF RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fb05c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "for metric in metricsComparison:\n",
    "    for m in metricsComparison[metric]:\n",
    "        final_dict[metric] = m\n",
    "mc_df = pd.DataFrame(final_dict)\n",
    "mc_df.plot.box(return_type='axes', figsize=(40,20), grid=True, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3d5f0",
   "metadata": {},
   "source": [
    "## FEATURES GRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78de2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "[11910.223708, 14923.715174, 16885.578943]\n",
    "\n",
    "x = [\"Challenger\", \"Master\", \"Champion\"]\n",
    "y_avg = [5166.317494, 8512.293683,11960.667065]\n",
    "y_STD = [5166.317494+(11910.223708/2), 8512.293683+(14923.715174/2), 11960.667065+(16885.578943/2)]\n",
    "y_std = [5166.317494-(11910.223708/2), 8512.293683-(14923.715174/2), 11960.667065-(16885.578943/2)]\n",
    "plt.plot(x,y_avg,marker=\"o\", label=\"avg\")\n",
    "plt.plot(x,y_STD,marker=\"o\", label=\"positive std\")\n",
    "plt.plot(x,y_std,marker=\"o\", label=\"negative std\")\n",
    "plt.title(\"synergy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf9a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [91.497714, 103.326571, 103.779429]\n",
    "x = [\"Champion\", \"Master\", \"Challenger\"]\n",
    "\n",
    "plt.plot(x,y,marker=\"o\")\n",
    "plt.title(\"level-sum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a0dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
