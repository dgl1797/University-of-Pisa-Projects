{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file = open(\"data_processing/paper_splits.json\", \"r\")\n",
    "paper_splits = json.loads(file.read())\n",
    "print(len(paper_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# import torch\n",
    "\n",
    "# model = SentenceTransformer(\n",
    "#     \"sentence-transformers/distilbert-base-nli-mean-tokens\",\n",
    "#     device=\"cuda\"\n",
    "#     if torch.cuda.is_available()\n",
    "#     else \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else \"cpu\",\n",
    "# )\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/allenai-specter').cuda() # this sentence transformer is the best so far and used in search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use chatgpt as a reference summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:06<00:00,  4.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for paper in tqdm(paper_splits):\n",
    "#     prompt = f\"summarize the following document with max 100 words: {paper['body_split']}\"\n",
    "#     openAIresponse = openai.ChatCompletion.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": prompt},\n",
    "#     ],\n",
    "#     max_tokens=128,\n",
    "#     temperature=0.8,\n",
    "#     )\n",
    "#     paper[\"reference_summary\"] = openAIresponse[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = open(\"paper_splits_output.json\", \"w\")\n",
    "# outfile.write(json.dumps(paper_splits))\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_splits_output = json.loads(open(file=\"paper_splits_output.json\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare current summary with another summarizer\n",
    "The current summarizer is bart pretrained on news, now we want to compare it with another trained on another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "INSTRUCTION = \"summarize the following article: \"\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"haining/scientific_abstract_simplification\")\n",
    "model2 = AutoModelForSeq2SeqLM.from_pretrained(\"haining/scientific_abstract_simplification\").cuda()\n",
    "\n",
    "for paper in paper_splits_output:\n",
    "    encoding = tokenizer2(paper[\"body_split\"], \n",
    "                        max_length=512,\n",
    "                        padding='max_length', \n",
    "                        truncation=True, \n",
    "                        return_tensors='pt')\n",
    "\n",
    "    decoded_ids = model2.generate(input_ids=encoding['input_ids'],\n",
    "                                attention_mask=encoding['attention_mask'], \n",
    "                                max_length=128, \n",
    "                                top_p=.9, \n",
    "                                do_sample=True)\n",
    "    \n",
    "    paper[\"summary_model2\"] = decoded_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for paper in tqdm(paper_splits_output):\n",
    "    paper[\"reference_encoding\"] = model.encode(paper[\"reference_summary\"])\n",
    "    paper[\"summary_encoding\"] = model.encode(paper[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import pandas as pd\n",
    "\n",
    "for split in paper_splits_output:\n",
    "    split[\"cosine_similarity\"] = cosine_similarity([split[\"reference_encoding\"]],[split[\"summary_encoding\"]])[0][0]\n",
    "    # split[\"euclidean_distance\"] = euclidean_distances([split[\"reference_encoding\"]],[split[\"summary_encoding\"]])[0][0]\n",
    "    print(split[\"cosine_similarity\"])\n",
    "    # if(split[\"cosine_similarity\"]<0):\n",
    "    #     print(split[\"title\"])\n",
    "\n",
    "# paper_splits[0].keys()\n",
    "df = pd.DataFrame.from_records(data=paper_splits_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8424217861890793\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.average(df[\"cosine_similarity\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
