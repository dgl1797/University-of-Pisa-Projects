{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from config import QDRANT_HOST, QDRANT_PORT, QDRANT_API_KEY, OPENAI_API_KEY, DATA, COLLECTION_NAME\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Qdrant and Mongo and create collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mongo_client = MongoClient('localhost', 27017)\n",
    "db = mongo_client.scientific_articles\n",
    "\n",
    "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, api_key=QDRANT_API_KEY)\n",
    "# client.recreate_collection(\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7135506f5c418e905989d805013146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "articles_json = list(db.articles.find({}))\n",
    "\n",
    "rows = []\n",
    "for paper in tqdm(articles_json): \n",
    "    rows.append(\n",
    "        (\n",
    "            paper[\"title\"],\n",
    "            paper[\"link\"],\n",
    "            paper[\"abstract\"],\n",
    "            paper[\"body\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(data=rows, columns=[\"title\", \"link\", \"abstract\", \"body\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciate Model\n",
    "Here we instantiate the sentence vectorizer and the word vectorizer, that will encode the papers that will be loaded into the retrieval system.\n",
    "We compare if using word or sentence vectorizer can bring some performance improvement into the similarity search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"msmarco-MiniLM-L-6-v3\",\n",
    "    device=\"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "\n",
    "for doc in tqdm(df[\"body\"].to_list()):\n",
    "    vectors.append(model.encode(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103\n"
     ]
    }
   ],
   "source": [
    "print(len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsplit = 100\n",
    "batch_load_step = int(df.shape[0]/nsplit)\n",
    "\n",
    "for index in list(range(nsplit)):\n",
    "    print(vectors[batch_load_step*index:batch_load_step*(index+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='papers_complete'), CollectionDescription(name='papers')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"papers\",\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data on Qdrant search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in list(range(nsplit)):\n",
    "    for _, row in df.iloc[list(range(batch_load_step*index, batch_load_step*(index+1)))].iterrows():\n",
    "        print(row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectors:\n",
    "    print((list(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in tqdm(list(range(nsplit))):\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=models.Batch(\n",
    "            ids=list(range(batch_load_step*index, batch_load_step*(index+1))),\n",
    "            payloads=[\n",
    "                {\n",
    "                    \"body\": row[\"body\"],\n",
    "                    \"abstract\": row[\"abstract\"],\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"link\": row[\"link\"],\n",
    "                }\n",
    "                for _, row in df.iloc[list(range(batch_load_step*index, batch_load_step*(index+1)))].iterrows()\n",
    "            ],\n",
    "            vectors= [vec.tolist() for vec in vectors[batch_load_step*index:batch_load_step*(index+1)]],\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'query' (str)\n"
     ]
    }
   ],
   "source": [
    "query = \"artificial intelligence medical applications?\"\n",
    "%store query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'similar_docs' (list)\n"
     ]
    }
   ],
   "source": [
    "similar_docs = client.search(\n",
    "        collection_name=\"papers_complete\",\n",
    "        query_vector=model.encode(query),\n",
    "        limit=6,\n",
    "        offset=0,\n",
    "        append_payload=True,\n",
    "    )\n",
    "\n",
    "%store similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5947627] Applications of Artificial Intelligence in the Radiology Roundtrip: Process Streamlining, Workflow Optimization, and Beyond\n",
      "[0.58876115] Artificial Intelligence for Cybersecurity: Literature Review and Future Research Directions\n",
      "[0.5600363] A systematic approach to enhance the explainability of artificial intelligence in healthcare with application to diagnosis of diabetes\n",
      "[0.53150547] Artificial intelligence for visually impaired\n",
      "[0.5301596] How artificial intelligence uses to achieve the agriculture sustainability: Systematic review\n",
      "[0.52678156] Artificial intelligence for secondary prevention of myocardial infarction: A qualitative study of patient and health professional perspectives\n"
     ]
    }
   ],
   "source": [
    "for doc in similar_docs: \n",
    "    print(\"[\" + str(doc.score) + '] ' + doc.payload['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f7d7ce7694bb4f4c294d506e5b6dc7957106f5332d820f0757e3d8cd7b1bbf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
