{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting OpenAI Chat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and configure openai key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r query\n",
    "%store -r text_summaries\n",
    "%store -r similar_docs\n",
    "\n",
    "\n",
    "def build_prompt():\n",
    "    prompt = \"You have been asked: \" + query + \" by a phd researcher. Provide a 1000 word answer with introduction, discussion and conclusions considering the following pieces of articles found on sciencedirect, mentioning them if necessary like this: [0], [1] and so on:\\n\" \n",
    "\n",
    "    for index, doc in enumerate(similar_docs):\n",
    "        prompt += f'{index}. title: \"{doc.payload[\"title\"]}\" {doc.payload[\"sentence\"]}\\n'\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt()\n",
    "print(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAIresponse = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"write a 4 lines lorem ipsum\"},\n",
    "    ],\n",
    "    max_tokens=2000,\n",
    "    temperature=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin auctor facilisis felis, id commodo lacus vehicula ut. Donec commodo, ipsum sit amet eleifend dignissim, erat ex porta ligula, ac finibus elit neque sit amet ex. Nulla facilisi.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1693986507,\n",
      "  \"id\": \"chatcmpl-7vhYxUdENaE6EaHywUIbMqYLk9UM6\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 64,\n",
      "    \"prompt_tokens\": 14,\n",
      "    \"total_tokens\": 78\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(openAIresponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
